{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84fc4ce",
   "metadata": {},
   "source": [
    "## Decision Trees (Classification)\n",
    "\n",
    "All decision trees work in basically the same way. Imagine we have data matrix X with $n$ samples and $d$ features. $X \\in \\mathbb{R}^{n\\times d}$\n",
    "\n",
    "1. Pick a feature based on some splitting criterion\n",
    "2. Divide dataset based on feature, each branch has that data\n",
    "3. Recurse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7988b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from abc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661cecf1",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b25cdba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SibSp\n",
       "0    608\n",
       "1    209\n",
       "2     28\n",
       "4     18\n",
       "3     16\n",
       "8      7\n",
       "5      5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"datasets/titanic_train.csv\")\n",
    "test = pd.read_csv(\"datasets/titanic_test.csv\")\n",
    "\n",
    "X_train, y_train = train.drop([\"Survived\", \"Name\", \"Ticket\", \"Cabin\", \"PassengerId\", \"Parch\"], axis=1), train['Survived']\n",
    "#X_train['Age'].hist(bins=10)\n",
    "X_train['SibSp'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "9ced785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_threshold(data, N):\n",
    "    thresholds = data.quantile([i / N for i in range(1, N)])\n",
    "    def map_func(x):\n",
    "        for i, val in enumerate(thresholds):\n",
    "            if x <= val:\n",
    "                return i\n",
    "        return N-1\n",
    "    return data.map(map_func)\n",
    "        \n",
    "\n",
    "def categorize_titanic(X):\n",
    "    df = X.copy()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].isna().any():\n",
    "            majority_value = df[column].mode().iloc[0]  # Get the most frequent value\n",
    "            df[column] = df[column].fillna(majority_value)\n",
    "    \n",
    "    df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
    "    df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "    df['Pclass'] = df['Pclass'].map({1: 0, 2: 1, 3: 2})\n",
    "    df['Fare'] = quantile_threshold(df['Fare'], 3)\n",
    "    df['Age'] = quantile_threshold(df['Age'], 2)\n",
    "    df['SibSp'] = df['SibSp'].map({0: 0, 1: 1, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2, 8: 2})\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "c86c9fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      False\n",
       "Sex         False\n",
       "Age         False\n",
       "SibSp       False\n",
       "Fare        False\n",
       "Embarked    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = train.drop([\"Survived\", \"Name\", \"Ticket\", \"Cabin\", \"PassengerId\", \"Parch\"], axis=1), train['Survived']\n",
    "X_train = categorize_titanic(X_train)\n",
    "\n",
    "X_train.isna().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "93b11273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop([ \"Name\", \"Ticket\", \"Cabin\", \"PassengerId\", \"Parch\"], axis=1)\n",
    "X_test = categorize_titanic(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c357b15",
   "metadata": {},
   "source": [
    "### Splitting Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943378a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_value_map = {\n",
    "    'Sex': {0: 'female', 1: 'male'},\n",
    "    'Embarked': {0: 'Southampton', 1: 'Cherbourg', 2: 'Queenstown'},\n",
    "    'Pclass': {0: \"first\", 1: \"second\", 2: \"third\"},\n",
    "    'Fare': {0: 'low', 1: 'medium', 2: 'high'},\n",
    "    'Age': {0: 'young', 1: 'old'},\n",
    "    'SibSp': {0: '0', 1: '1', 2: '2+'}\n",
    "}\n",
    "\n",
    "def get_varcode(feature, value):\n",
    "    vals = variable_value_map[feature]\n",
    "    for key, val in vals.items():\n",
    "        if isinstance(value, str) and val == value:\n",
    "            return key\n",
    "        elif isinstance(value, int) and key == value:\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "get_varcode('Sex', 'male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d57637d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.4999999956719148)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def entropy(y):\n",
    "    probs = y.value_counts(normalize=True)\n",
    "    return -1 * np.sum(probs * np.log2(probs + 1e-9))\n",
    "\n",
    "def classification_error(y):\n",
    "    return 1 - y.value_counts().max() / y.count()\n",
    "\n",
    "def gini_index(y):\n",
    "    N = y.count()\n",
    "    return 1 - y.value_counts().pow(2).sum() / N**2\n",
    "\n",
    "entropy(pd.Series([2,1,0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58555878",
   "metadata": {},
   "source": [
    "### Tree Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a5906ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Sex'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b96eed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_measures = {\n",
    "\t'entropy': entropy,\n",
    "\t'classification_error': classification_error,\n",
    "\t'gini_index': gini_index\n",
    "}\n",
    "\n",
    "class DecisionTree:\n",
    "\tdef __init__(self, data, labels, uncertainty_measure='entropy'):\n",
    "\t\tself.X = data\n",
    "\t\tself.y = labels\n",
    "\t\tself.features = list(data.columns)\n",
    "\t\tself.N = data.shape[0]\n",
    "\t\tself.uncertainty_measure = uncertainty_measure\n",
    "\t\tself.uncertainty_func = uncertainty_measures[uncertainty_measure]\n",
    "\t\tself.splitting_feature = None\n",
    "\t\tself.children = []\n",
    "\t\tself.is_leaf = (len(self.features) == 1) or self.N < 5\n",
    "\t\n",
    "\t@abstractmethod\n",
    "\tdef _splits(self, feature):\n",
    "\t\tpass\n",
    "\n",
    "\tdef Information_Gain(self, feature):\n",
    "\t\tdata = self.X[feature]\n",
    "\t\tG = self.uncertainty_func(self.y)\n",
    "\t\tfor split in self._splits(feature):\n",
    "\t\t\tG -= split.size / self.N * self.uncertainty_func(split)\n",
    "\t\treturn G\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f06cfee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, np.float64(0.6161616161616161))"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_counts = y_train.value_counts(normalize=True)\n",
    "y_counts.idxmax().item(), y_counts[y_counts.idxmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "20f893e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CategoricalDecisionTree(DecisionTree):\n",
    "\tdef __init__(self, data, labels, uncertainty_measure='entropy'):\n",
    "\t\tsuper().__init__(data, labels, uncertainty_measure)\n",
    "\t\tself.children = {}\n",
    "\t\t#self.gains = {feature : self.Information_Gain(feature) for feature in self.features}\n",
    "\t\tif(self.N > 0):\n",
    "\t\t\tself.fit()\n",
    "\t\n",
    "\tdef _splits(self, feature):\n",
    "\t\tres = []\n",
    "\t\tfor i in self.X[feature].unique():\n",
    "\t\t\tres.append(self.y[self.X[feature] == i].reset_index(drop=True))\n",
    "\t\treturn res\n",
    "\t\n",
    "\tdef select_splitting_feature(self):\n",
    "\t\tmax_gain = 0\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tgain = self.Information_Gain(feature)\n",
    "\t\t\tif gain > max_gain:\n",
    "\t\t\t\tmax_gain = gain\n",
    "\t\t\t\tself.splitting_feature = feature\n",
    "\t\tif(self.splitting_feature is None):\n",
    "\t\t\tgains = {feature : self.Information_Gain(feature) for feature in self.features}\n",
    "\t\t\tprint(\"No gain acheived, need to diagnose \", gains)\n",
    "\t\t\tself.weird = True\n",
    "\t\treturn max_gain\n",
    "\n",
    "\t\n",
    "\tdef fit(self, debug=False):\n",
    "\t\ty_probs = self.y.value_counts(normalize=False)\n",
    "\t\tif(debug):\n",
    "\t\t\tprint(f\"\\nfitting node with y_probs={dict(y_probs)} samples on features {self.features}\")\n",
    "\t\tmajority_yval = y_probs.idxmax().item()\n",
    "\t\tif(y_probs[majority_yval] / self.N > 0.85 or self.N < 5):\n",
    "\t\t\tif(debug):\n",
    "\t\t\t\tprint(\"Enforcing leaf node due to purity\")\n",
    "\t\t\tself.is_leaf = True\n",
    "\t\t\n",
    "\t\tif self.is_leaf:\n",
    "\t\t\tself.predictions = {}\n",
    "\t\t\tself.splitting_feature = self.features[0]\n",
    "\t\t\tfor xval in variable_value_map[self.splitting_feature].keys():\n",
    "\t\t\t\ty = self.y[self.X[self.splitting_feature] == xval]\n",
    "\t\t\t\tif(y.size > 1):\n",
    "\t\t\t\t\tself.predictions[int(xval)] = y.value_counts().idxmax().item()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.predictions[int(xval)] = majority_yval\n",
    "\t\t\tif(debug):\n",
    "\t\t\t\tprint(f\"Leaf node on {self.splitting_feature}, predictions: {self.predictions}\")\n",
    "\t\t\treturn\n",
    "\t\t\n",
    "\t\tmax_gain = self.select_splitting_feature()\n",
    "\t\tif(debug):\n",
    "\t\t\tprint(f\"Choosing to split on {self.splitting_feature} with gain {max_gain}\")\n",
    "\t\t\n",
    "\t\tfor xval in self.X[self.splitting_feature].unique():\n",
    "\t\t\tbool_mask = self.X[self.splitting_feature] == xval\n",
    "\t\t\tsample = self.X[bool_mask].drop(columns=[self.splitting_feature]).reset_index(drop=True)\n",
    "\t\t\tnew_label = self.y[bool_mask].reset_index(drop=True)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tself.children[int(xval)] = CategoricalDecisionTree(sample, new_label, self.uncertainty_measure)\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(f\"Error fitting child with x value {xval}, {e}\")\n",
    "\t\t\t\tself.weird = True\n",
    "\n",
    "\tdef predict_row(self, row, indent_level=0, verbose=False):\n",
    "\t\trval = int(row[self.splitting_feature])\n",
    "\t\tif not self.is_leaf:\n",
    "\t\t\tspace = \"   \" * indent_level\n",
    "\t\t\tif verbose:\n",
    "\t\t\t\tprint(f\"{space} -->{self.splitting_feature} is {variable_value_map[self.splitting_feature][rval]} ({rval})\")\n",
    "\t\t\treturn self.children[rval].predict_row(row, indent_level + 1, verbose)\n",
    "\t\tpred = self.predictions[rval]\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"And so finally, because {self.splitting_feature} is {variable_value_map[self.splitting_feature][rval]} ({rval}), the prediction is {pred}\")\n",
    "\t\treturn pred\n",
    "\n",
    "\tdef predict(self, data):\n",
    "\t\tpreds = []\n",
    "\t\tfor i, row in data.iterrows():\n",
    "\t\t\tpreds.append(self.predict_row(row, verbose=False))\n",
    "\t\treturn np.array(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "aa49db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = CategoricalDecisionTree(X_train, y_train)\n",
    "tree.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "ba8d97ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " Pclass      0\n",
       " Sex         1\n",
       " Age         1\n",
       " SibSp       0\n",
       " Fare        2\n",
       " Embarked    0\n",
       " Name: 6, dtype: int64)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = X_train.iloc[6]\n",
    "y_train.iloc[6].item(), row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "40b81a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -->Sex is male (1)\n",
      "    -->Fare is high (2)\n",
      "       -->SibSp is 0 (0)\n",
      "          -->Pclass is first (0)\n",
      "             -->Age is old (1)\n",
      "And so finally, because Embarked is Southampton (0), the prediction is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict_row(row, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "91f63b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8383838383838383)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tree.predict(X_train) == y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "3105d848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "59e5ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Sex is male (1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: <__main__.CategoricalDecisionTree at 0x2925cc890>,\n",
       " 0: <__main__.CategoricalDecisionTree at 0x2912c8890>}"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr = tree\n",
    "rval = int(row[curr.splitting_feature])\n",
    "print(f\"--> {curr.splitting_feature} is {variable_value_map[curr.splitting_feature][rval]} ({rval})\")\n",
    "curr.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "c7d5975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Embarked is Southampton (0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, {})"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr = curr.children[rval]\n",
    "rval = int(row[curr.splitting_feature])\n",
    "print(f\"--> {curr.splitting_feature} is {variable_value_map[curr.splitting_feature][rval]} ({rval})\")\n",
    "curr.is_leaf, curr.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "d64ef357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0, 1: 0, 2: 0}, 'Embarked')"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr.predictions, curr.splitting_feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
